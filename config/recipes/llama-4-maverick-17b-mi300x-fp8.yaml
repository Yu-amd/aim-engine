recipe_id: llama-4-maverick-17b-mi300x-fp8
model_id: meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8
huggingface_id: meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8
hardware: MI300X
precision: fp8
vllm_serve:
  1_gpu:
    enabled: true
    args:
      --model: meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8
      --dtype: float8_e5m2
      --gpu-memory-utilization: '0.9'
      --trust-remote-code: 'true'
      --port: '8000'
      --max-num-batched-tokens: '16384'
      --max-model-len: '131072'
  2_gpu:
    enabled: true
    args:
      --model: meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8
      --dtype: float8_e5m2
      --tensor-parallel-size: '2'
      --gpu-memory-utilization: '0.9'
      --trust-remote-code: 'true'
      --port: '8000'
      --max-num-batched-tokens: '32768'
      --max-model-len: '131072'
  4_gpu:
    enabled: true
    args:
      --model: meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8
      --dtype: float8_e5m2
      --tensor-parallel-size: '4'
      --gpu-memory-utilization: '0.9'
      --trust-remote-code: 'true'
      --port: '8000'
      --max-num-batched-tokens: '65536'
      --max-model-len: '131072'
  8_gpu:
    enabled: true
    args:
      --model: meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8
      --dtype: float8_e5m2
      --tensor-parallel-size: '8'
      --gpu-memory-utilization: '0.9'
      --trust-remote-code: 'true'
      --port: '8000'
      --max-num-batched-tokens: '131072'
      --max-model-len: '131072'
sglang_serve:
  1_gpu:
    enabled: true
    args:
      --model: meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8
      --dtype: float8_e5m2
      --gpu-memory-utilization: '0.9'
      --trust-remote-code: 'true'
      --port: '8001'
      --max-num-batched-tokens: '8192'
      --max-model-len: '131072'
  2_gpu:
    enabled: true
    args:
      --model: meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8
      --dtype: float8_e5m2
      --tensor-parallel-size: '2'
      --gpu-memory-utilization: '0.9'
      --trust-remote-code: 'true'
      --port: '8001'
      --max-num-batched-tokens: '16384'
      --max-model-len: '131072'
  4_gpu:
    enabled: true
    args:
      --model: meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8
      --dtype: float8_e5m2
      --tensor-parallel-size: '4'
      --gpu-memory-utilization: '0.9'
      --trust-remote-code: 'true'
      --port: '8001'
      --max-num-batched-tokens: '32768'
      --max-model-len: '131072'
  8_gpu:
    enabled: true
    args:
      --model: meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8
      --dtype: float8_e5m2
      --tensor-parallel-size: '8'
      --gpu-memory-utilization: '0.9'
      --trust-remote-code: 'true'
      --port: '8001'
      --max-num-batched-tokens: '65536'
      --max-model-len: '131072'
