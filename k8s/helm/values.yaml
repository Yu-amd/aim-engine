# Default values for aim-engine
# This is a YAML-formatted file.

# Global configuration
global:
  environment: development
  imageRegistry: ""
  imagePullSecrets: []
  storageClass: ""

# AIM Engine specific configuration
aim_engine:
  # Recipe selection configuration
  recipe:
    model_id: "Qwen/Qwen3-32B"
    auto_select: true  # Let AIM Engine select optimal recipe
    gpu_count: null    # Will be determined by recipe if auto_select: true
    precision: null    # Will be determined by recipe if auto_select: true
    backend: "vllm"    # Backend to use (vllm, sglang)
    fallback_enabled: true
    constraints:
      max_gpu_count: 8
      min_gpu_count: 1
      preferred_precision: "bf16"
    
    # Configuration overrides (takes precedence over auto-selection)
    overrides:
      enabled: false  # Enable to override auto-selected configuration
      gpu_count: null  # Override GPU count
      precision: null  # Override precision (bf16, fp16, fp8)
      backend: null    # Override backend
      vllm_args: {}    # Override specific vLLM arguments
      env_vars: {}     # Override environment variables
  
  # Resource configuration
  resources:
    gpu_count: 4  # Default, will be overridden by recipe if auto_select: true
    memory_multiplier: 16  # Gi per GPU
    cpu_multiplier: 4      # CPU cores per GPU
  
  # Performance tuning
  performance:
    gpu_memory_utilization: 0.9
    max_model_len: 32768
    batch_token_scaling: true
  
  # Hardware configuration
  hardware:
    type: "MI300X"
    rocm_arch: "gfx90a"
    precision: "bf16"
  
  # vLLM configuration (will be populated from recipe)
  vllm:
    args: {}  # Will be populated from selected recipe
    env: {}   # Will be populated from selected recipe

# Image configuration
image:
  repository: aim-vllm
  tag: latest
  pullPolicy: IfNotPresent

# Image pull secrets
imagePullSecrets: []

# Service account configuration
serviceAccount:
  create: true
  name: "aim-engine-sa"
  annotations: {}

# Pod security context
podSecurityContext:
  runAsUser: 0
  runAsGroup: 0
  fsGroup: 0

# Container security context
securityContext:
  privileged: true
  allowPrivilegeEscalation: true
  capabilities:
    add:
      - SYS_ADMIN

# Liveness probe configuration
livenessProbe:
  enabled: false
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

# Readiness probe configuration
readinessProbe:
  enabled: false
  initialDelaySeconds: 5
  periodSeconds: 5
  timeoutSeconds: 3
  failureThreshold: 3

# Pod annotations
podAnnotations: {}

# Pod labels
podLabels: {}

# Node selector
nodeSelector:
  amd.com/gpu: "true"
  kubernetes.io/os: linux

# Tolerations
tolerations:
  - key: node-role.kubernetes.io/control-plane
    operator: Exists
    effect: NoSchedule
  - key: amd.com/gpu
    operator: Exists
    effect: NoSchedule

# Affinity
affinity: {}

# Replica configuration
replicaCount:
  development: 1
  production: 2

# Resource configuration
resources:
  development:
    requests:
      cpu: 4
      memory: 16Gi
      amd.com/gpu: 2
    limits:
      cpu: 8
      memory: 32Gi
      amd.com/gpu: 2
  production:
    requests:
      cpu: 16
      memory: 64Gi
      amd.com/gpu: 8
    limits:
      cpu: 32
      memory: 128Gi
      amd.com/gpu: 8

# Service configuration
service:
  type: LoadBalancer
  port: 80
  targetPort: 8000
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
    service.beta.kubernetes.io/aws-load-balancer-scheme: "internet-facing"
    cloud.google.com/load-balancer-type: "External"
    service.beta.kubernetes.io/azure-load-balancer-internal: "false"

# Ingress configuration
ingress:
  enabled: true
  className: "nginx"
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    nginx.ingress.kubernetes.io/proxy-body-size: "50m"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "300"
    nginx.ingress.kubernetes.io/rate-limit: "100"
    nginx.ingress.kubernetes.io/rate-limit-window: "1m"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
  hosts:
    - host: aim-engine.your-domain.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: aim-engine-tls
      hosts:
        - aim-engine.your-domain.com

# Persistence configuration
persistence:
  enabled: true
  storageClass: ""
  accessMode: ReadWriteMany
  size: 500Gi
  mountPath: /workspace/model-cache

# Configuration
config:
  # AIM Engine configuration
  aim_cache_dir: "/workspace/model-cache"
  aim_cache_enabled: "1"
  
  # Hugging Face configuration
  hf_home: "/workspace/model-cache"
  transformers_cache: "/workspace/model-cache"
  hf_datasets_cache: "/workspace/model-cache"
  vllm_cache_dir: "/workspace/model-cache"
  hf_hub_disable_telemetry: "1"
  
  # ROCm/AMD GPU configuration
  hip_visible_devices: "0,1,2,3,4,5,6,7"
  pytorch_rocm_arch: "gfx90a"
  vllm_use_rocm: "1"
  
  # Performance optimization
  pytorch_cuda_alloc_conf: "max_split_size_mb:512"
  
  # Default model configuration
  default_model: "Qwen/Qwen3-32B"
  default_gpu_count: "4"
  default_precision: "fp16"
  default_port: "8000"
  
  # Health check configuration
  health_check_path: "/health"
  readiness_timeout: "30"
  liveness_timeout: "60"

# Environment variables
env:
  - name: PYTHONUNBUFFERED
    value: "1"
  - name: ENVIRONMENT
    value: "development"
  - name: LOG_LEVEL
    value: "INFO"
  - name: MAX_CONCURRENT_REQUESTS
    value: "100"

# Secrets
secrets:
  enabled: false
  data: {}
  # Example:
  # data:
  #   API_KEY: "your-api-key"
  #   HF_TOKEN: "your-huggingface-token"

# Health checks
healthChecks:
  livenessProbe:
    enabled: true
    httpGet:
      path: /health
      port: 8000
    initialDelaySeconds: 120
    periodSeconds: 30
    timeoutSeconds: 10
    failureThreshold: 3
  
  readinessProbe:
    enabled: true
    httpGet:
      path: /health
      port: 8000
    initialDelaySeconds: 60
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3
  
  startupProbe:
    enabled: true
    httpGet:
      path: /health
      port: 8000
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 30

# Horizontal Pod Autoscaler
hpa:
  enabled: true
  minReplicas: 1
  maxReplicas: 5
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
        - type: Percent
          value: 10
          periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
        - type: Percent
          value: 100
          periodSeconds: 15
        - type: Pods
          value: 2
          periodSeconds: 15

# Monitoring configuration
monitoring:
  enabled: true
  serviceMonitor:
    enabled: true
    interval: 30s
    scrapeTimeout: 10s
    honorLabels: true
  
  prometheusRule:
    enabled: true
    groups:
      - name: aim-engine.rules
        rules:
          - alert: AIMEngineDown
            expr: up{app="aim-engine"} == 0
            for: 1m
            labels:
              severity: critical
            annotations:
              summary: "AIM Engine is down"
              description: "AIM Engine has been down for more than 1 minute"
          
          - alert: AIMEngineHighCPU
            expr: container_cpu_usage_seconds_total{container="aim-engine"} > 80
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "AIM Engine high CPU usage"
              description: "AIM Engine CPU usage is above 80% for 5 minutes"
          
          - alert: AIMEngineHighMemory
            expr: container_memory_usage_bytes{container="aim-engine"} / container_spec_memory_limit_bytes{container="aim-engine"} > 0.8
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "AIM Engine high memory usage"
              description: "AIM Engine memory usage is above 80% for 5 minutes"

# RBAC configuration
rbac:
  create: true
  clusterRole:
    create: true
    rules:
      - apiGroups: [""]
        resources: ["pods", "services", "endpoints", "persistentvolumeclaims", "events", "configmaps", "secrets"]
        verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
      - apiGroups: ["apps"]
        resources: ["deployments", "replicasets", "statefulsets"]
        verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
      - apiGroups: ["autoscaling"]
        resources: ["horizontalpodautoscalers"]
        verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
      - apiGroups: ["networking.k8s.io"]
        resources: ["ingresses", "ingressclasses"]
        verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
      - apiGroups: [""]
        resources: ["nodes"]
        verbs: ["get", "list", "watch"]

# Network policy
networkPolicy:
  enabled: false
  ingress:
    - from:
        - namespaceSelector:
            matchLabels:
              name: ingress-nginx
      ports:
        - protocol: TCP
          port: 8000

# Pod disruption budget
podDisruptionBudget:
  enabled: false
  minAvailable: 1
  maxUnavailable: 1

# Priority class
priorityClassName: ""

# Termination grace period
terminationGracePeriodSeconds: 30

# Update strategy
updateStrategy:
  type: RollingUpdate
  rollingUpdate:
    maxSurge: 1
    maxUnavailable: 0

# Pod management policy
podManagementPolicy: OrderedReady

# Volume mounts
volumeMounts:
  - name: model-cache
    mountPath: /workspace/model-cache
  - name: kfd-device
    mountPath: /dev/kfd
  - name: dri-device
    mountPath: /dev/dri

# Volumes
volumes:
  - name: kfd-device
    hostPath:
      path: /dev/kfd
  - name: dri-device
    hostPath:
      path: /dev/dri 