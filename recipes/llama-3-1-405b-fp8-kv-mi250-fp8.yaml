recipe_id: llama-3-1-405b-fp8-kv-mi250-fp8
model_id: amd/Llama-3.1-405B-Instruct-FP8-KV
huggingface_id: amd/Llama-3.1-405B-Instruct-FP8-KV
hardware: MI250
precision: fp8
vllm_serve:
  1_gpu:
    enabled: true
    args:
      --model: amd/Llama-3.1-405B-Instruct-FP8-KV
      --dtype: float8_e4m3
      --gpu-memory-utilization: '0.9'
      --trust-remote-code: 'true'
      --port: '8000'
      --max-num-batched-tokens: '1024'
      --max-model-len: '8192'
  2_gpu:
    enabled: true
    args:
      --model: amd/Llama-3.1-405B-Instruct-FP8-KV
      --dtype: float8_e4m3
      --tensor-parallel-size: '2'
      --gpu-memory-utilization: '0.9'
      --trust-remote-code: 'true'
      --port: '8000'
      --max-num-batched-tokens: '1024'
      --max-model-len: '8192'
  4_gpu:
    enabled: true
    args:
      --model: amd/Llama-3.1-405B-Instruct-FP8-KV
      --dtype: float8_e4m3
      --tensor-parallel-size: '4'
      --gpu-memory-utilization: '0.9'
      --trust-remote-code: 'true'
      --port: '8000'
      --max-num-batched-tokens: '2048'
      --max-model-len: '8192'
  8_gpu:
    enabled: true
    args:
      --model: amd/Llama-3.1-405B-Instruct-FP8-KV
      --dtype: float8_e4m3
      --tensor-parallel-size: '8'
      --gpu-memory-utilization: '0.9'
      --trust-remote-code: 'true'
      --port: '8000'
      --max-num-batched-tokens: '4096'
      --max-model-len: '8192'
sglang_serve:
  1_gpu:
    enabled: true
    args:
      --model: amd/Llama-3.1-405B-Instruct-FP8-KV
      --dtype: float8_e4m3
      --gpu-memory-utilization: '0.9'
      --trust-remote-code: 'true'
      --port: '8001'
      --max-num-batched-tokens: '1024'
      --max-model-len: '8192'
  2_gpu:
    enabled: true
    args:
      --model: amd/Llama-3.1-405B-Instruct-FP8-KV
      --dtype: float8_e4m3
      --tensor-parallel-size: '2'
      --gpu-memory-utilization: '0.9'
      --trust-remote-code: 'true'
      --port: '8001'
      --max-num-batched-tokens: '1024'
      --max-model-len: '8192'
  4_gpu:
    enabled: true
    args:
      --model: amd/Llama-3.1-405B-Instruct-FP8-KV
      --dtype: float8_e4m3
      --tensor-parallel-size: '4'
      --gpu-memory-utilization: '0.9'
      --trust-remote-code: 'true'
      --port: '8001'
      --max-num-batched-tokens: '1024'
      --max-model-len: '8192'
  8_gpu:
    enabled: true
    args:
      --model: amd/Llama-3.1-405B-Instruct-FP8-KV
      --dtype: float8_e4m3
      --tensor-parallel-size: '8'
      --gpu-memory-utilization: '0.9'
      --trust-remote-code: 'true'
      --port: '8001'
      --max-num-batched-tokens: '2048'
      --max-model-len: '8192'
